{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e79eb86-17a9-43e6-baf6-200aa19e2ed4",
   "metadata": {},
   "source": [
    "***\n",
    "# <center>***Part of speech Tagging***\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f088bc1-ae26-43fe-be17-96515ca16275",
   "metadata": {},
   "source": [
    "## ***I learned the following natural language processing techniques:***\n",
    "\n",
    "- [Default tagging](#Default-tagging)  \n",
    "- [Training a unigram part-of-speech tagger](#Training-a-unigram-part-of-speech-tagger)  \n",
    "- [Combining taggers with backoff tagging](#Combining-taggers-with-backoff-tagging)  \n",
    "- [Training and combining ngram taggers](#Training-and-combining-ngram-taggers)  \n",
    "- [Creating a model of likely word tags](#Creating-a-model-of-likely-word-tags)  \n",
    "- [Tagging with regular expressions](#Tagging-with-regular-expressions)  \n",
    "- [Affix tagging](#Affix-tagging)  \n",
    "- [Training a Brill tagger](#Training-a-Brill-tagger)  \n",
    "- [Training the TnT tagger](#Training-the-TnT-tagger)  \n",
    "- [Using WordNet for tagging](#Using-WordNet-for-tagging)  \n",
    "- [Tagging proper names](#Tagging-proper-names)  \n",
    "- [Classifier-based tagging](#Classifier-based-tagging)  \n",
    "- [Training a tagger with NLTK-Trainer](#Training-a-tagger-with-NLTK-Trainer)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1842437-cb88-4c70-b97d-305a39244693",
   "metadata": {},
   "source": [
    "**Part-of-speech tagging** is the process of converting a sentence, in the form of a list of words, into a list of tuples, where each tuple is of the form (word, tag). The tag is a part-of-speech tag, and signifies whether the word is a noun, adjective, verb, and so on. Part-of-speech tagging is a necessary step before chunking. Without the part-of-speech tags, a chunker cannot know how to extract \n",
    "phrases from a sentence. But with part-of-speech tags, you can tell a chunker how to identify phrases based on tag patterns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e184d2-1edc-42bf-8d5a-a15a07eeefd7",
   "metadata": {},
   "source": [
    "***\n",
    "## ***<a id=\"Default-tagging\"></a>Default tagging:***\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3ef186-d4c1-4a27-8c49-c55bd17a0929",
   "metadata": {},
   "source": [
    "**Default tagging** provides a baseline for part-of-speech tagging. It simply assigns the same part-of-speech tag to every token. We do this using the DefaultTagger class. This tagger  is useful as a last-resort tagger, and provides a baseline to measure accuracy improvements.\n",
    "\n",
    "We are going to use the **treebank** corpus because it is a common standard and is quick to load and test. But everything we do should apply equally well to **brown**, **conll2000**, and any other part-of-speech tagged corpus.\n",
    "\n",
    "The **`DefaultTagger`** class takes a single argument, the tag you want to apply. We will give it **NN**, which is the tag for a singular noun. **DefaultTagger** is most useful when you choose the most common part-of-speech tag. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef60be42-1714-44dd-ad1b-27f3150ae02a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hello', 'NN'), ('World', 'NN')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from nltk.tag import DefaultTagger\n",
    "tagger = DefaultTagger('NN')\n",
    "tagger.tag(['Hello', 'World'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a456b09-72bd-4fe2-9fb4-1615cc5f7995",
   "metadata": {},
   "source": [
    "Every **tagger** has a **tag()** method that takes a list of tokens, where each token is a single word. This list of tokens is usually a list of words produced by a word tokenizer. As you can see, **tag()** returns a list of **tagged tokens**, where a tagged token is a tuple of **(word, tag)**.\n",
    "\n",
    "***`DefaultTagger`*** is a subclass of ***`SequentialBackoffTagger`***. Every subclass of **SequentialBackoffTagger** must implement the choose_tag() method, which takes three arguments:\n",
    " - The list of tokens\n",
    " - The index of the current token whose tag we want to choose\n",
    " - The history, which is a list of the previous tags\n",
    "\n",
    "SequentialBackoffTagger implements the tag() method, which calls the choose_tag() method of the subclass for each index in the tokens list while accumulating a history of the previously tagged tokens. This history is the reason for the Sequential in  SequentialBackoffTagger. We'll get to the backoff portion of the name in the Combining taggers with backoff tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634d66ff-6402-414e-9aed-5b5879f897f6",
   "metadata": {},
   "source": [
    "**Evaluating accuracy:**  \n",
    "\n",
    "To know how accurate a tagger is, you can use the evaluate() method, which takes a list \n",
    "of tagged tokens as a gold standard to evaluate the tagger. Using our default tagger created \n",
    "earlier, we can evaluate it against a subset of the treebank corpus tagged sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35449392-3812-4039-928f-9c95db6baba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14331966328512843"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from nltk.corpus import treebank\n",
    "test_sents = treebank.tagged_sents()[3000:]\n",
    "tagger.evaluate(test_sents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4b43cc-e517-4071-8944-44b934e2802d",
   "metadata": {},
   "source": [
    "So, by just choosing **NN** for every tag, we can achieve **14%** accuracy testing on one-fourth of the treebank corpus. Of course, accuracy will be different if you choose a different default tag."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14c6985-f0aa-4586-97f6-679a2bbee444",
   "metadata": {},
   "source": [
    "**Tagging sentences:**\n",
    "\n",
    "**TaggerI** also implements a **tag_sents()** method that can be used to tag a list of sentences, instead of a single sentence. Here is an example of tagging two simple sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbc4b156-f438-40f4-a22a-205f9b66f43f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Hello', 'NN'), ('world', 'NN'), ('.', 'NN')],\n",
       " [('How', 'NN'), ('are', 'NN'), ('you', 'NN'), ('?', 'NN')]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tagger.tag_sents([['Hello', 'world', '.'], ['How', 'are', 'you', '?']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55cd21d-ff4f-4e15-b713-698b432a09cd",
   "metadata": {},
   "source": [
    "The result is a list of two `tagged sentences`, and of course, every tag is `NN` because we're using \n",
    "the DefaultTagger class. The `tag_sents()` method can be quiet useful if you have many \n",
    "sentences you wish to tag all at once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e51208f-01d5-4b94-91bc-735e7abd1fdf",
   "metadata": {},
   "source": [
    "**Untagging a tagged sentence:**\n",
    "\n",
    "Tagged sentences can be untagged using `nltk.tag.untag()`. Calling this function with  a tagged sentence will return a list of words without the tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05e9de7b-131e-4da6-9db5-dc1673d526d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'World']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from nltk.tag import untag\n",
    "untag([('Hello', 'NN'), ('World', 'NN')])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9888628d-ecd5-4f4f-b060-1abd02472e48",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "***\n",
    "## ***<a id=\"Training-a-unigram-part-of-speech-tagger\"></a>Training a unigram part-of-speech tagger:***\n",
    "***\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4019861-cdf2-4a6e-b773-40b637c2245e",
   "metadata": {},
   "source": [
    "A **unigram** generally refers to a single token. Therefore, a unigram tagger only uses a single word as its context for determining the part-of-speech tag. `UnigramTagger` inherits from `NgramTagger`, which is a subclass of `ContextTagger`, which inherits from `SequentialBackoffTagger`. In other words, `UnigramTagger` is a context-based tagger whose context is a single word, or unigram.\n",
    "\n",
    "**UnigramTagger** can be trained by giving it a list of tagged sentences at initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9760f9f1-ece6-4277-9330-9d1e89c60a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pierre',\n",
       " 'Vinken',\n",
       " ',',\n",
       " '61',\n",
       " 'years',\n",
       " 'old',\n",
       " ',',\n",
       " 'will',\n",
       " 'join',\n",
       " 'the',\n",
       " 'board',\n",
       " 'as',\n",
       " 'a',\n",
       " 'nonexecutive',\n",
       " 'director',\n",
       " 'Nov.',\n",
       " '29',\n",
       " '.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from nltk.tag import UnigramTagger\n",
    "from nltk.corpus import treebank\n",
    "train_sents = treebank.tagged_sents()[:3000]\n",
    "tagger = UnigramTagger(train_sents)\n",
    "treebank.sents()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81197306-e64d-49a2-a1b3-9791a76f7578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pierre', 'NNP'),\n",
       " ('Vinken', 'NNP'),\n",
       " (',', ','),\n",
       " ('61', 'CD'),\n",
       " ('years', 'NNS'),\n",
       " ('old', 'JJ'),\n",
       " (',', ','),\n",
       " ('will', 'MD'),\n",
       " ('join', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('board', 'NN'),\n",
       " ('as', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('nonexecutive', 'JJ'),\n",
       " ('director', 'NN'),\n",
       " ('Nov.', 'NNP'),\n",
       " ('29', 'CD'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tagger.tag(treebank.sents()[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94c115b-0ac8-4f33-8e50-11f4f2dbfdc0",
   "metadata": {},
   "source": [
    "We use the first 3000 tagged sentences of the treebank corpus as the training set to initialize the `UnigramTagger` class. Then, we see the first sentence as a list of words, and can see how it is transformed by the tag() function into a list of tagged tokens.\n",
    "\n",
    "Let's see how accurate the `UnigramTagger` class is on the test sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1e9f306-480c-46f9-8a56-84039e46ba31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8571551910209367"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tagger.evaluate(test_sents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab439626-5403-42b0-ae64-4f48b5226b70",
   "metadata": {},
   "source": [
    "It has almost `86%` accuracy for a tagger that only uses single word lookup to determine the part-of-speech tag. All accuracy gains from here on will be much smaller."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1f2467-600d-4a52-acf6-906ca6675940",
   "metadata": {},
   "source": [
    "**Overriding the context model:**\n",
    "\n",
    "All taggers that inherit from ContextTagger can take a pre-built model instead of training their own. This model is simply a Python dict mapping a context key to a tag. The context keys will depend on what the ContextTagger subclass returns from its context() method. For UnigramTagger, context keys are individual words. But for other NgramTagger subclasses, the context keys will be tuples.\n",
    "\n",
    "Here's an example where we pass a very simple model to the UnigramTagger class instead of a training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f508682-e672-4702-975c-96a7d6b3c0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pierre', 'NN'),\n",
       " ('Vinken', None),\n",
       " (',', None),\n",
       " ('61', None),\n",
       " ('years', None),\n",
       " ('old', None),\n",
       " (',', None),\n",
       " ('will', None),\n",
       " ('join', None),\n",
       " ('the', None),\n",
       " ('board', None),\n",
       " ('as', None),\n",
       " ('a', None),\n",
       " ('nonexecutive', None),\n",
       " ('director', None),\n",
       " ('Nov.', None),\n",
       " ('29', None),\n",
       " ('.', None)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tagger = UnigramTagger(model={'Pierre': 'NN'})\n",
    "tagger.tag(treebank.sents()[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f12d8f-569f-4dee-aaf6-ddf3a536bdab",
   "metadata": {},
   "source": [
    "**Minimum frequency cutoff:**\n",
    "\n",
    "The ContextTagger class uses frequency of occurrence to decide which tag is most likely for a given context. By default, it will do this even if the context word and tag occurs only once. If you would like to set a minimum frequency threshold, then you can pass a cutoff value to the `UnigramTagger` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b9761e1-fa15-49c0-8578-e210a7b1b74c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.775350744657889"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tagger = UnigramTagger(train_sents, cutoff=3)\n",
    "tagger.evaluate(test_sents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c0be45-739a-40de-be0a-9ff1c5843ecf",
   "metadata": {},
   "source": [
    "\n",
    "***\n",
    "## ***<a id=\"Combining-taggers-with-backoff-tagging\"></a>Combining taggers with backoff tagging:***\n",
    "***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf637284-65bd-4cae-bd11-cc873dac5fdd",
   "metadata": {},
   "source": [
    "**Backoff tagging** is one of the core features of `SequentialBackoffTagger`. It allows you to chain taggers together so that if one tagger doesn't know how to tag a word, it can pass the word on to the next backoff tagger. If that one can't do it, it can pass the word on to the next backoff tagger, and so on until there are no backoff taggers left to check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c84fea71-c736-4f58-8868-187d935040b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8741204403194475"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tagger1 = DefaultTagger('NN')\n",
    "tagger2 = UnigramTagger(train_sents, backoff=tagger1)\n",
    "tagger2.evaluate(test_sents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89b116a-c87c-4d03-8893-a80fddf861bc",
   "metadata": {},
   "source": [
    "**Saving and loading a trained tagger with pickle:**\n",
    "\n",
    "Since training a tagger can take a while, and you generally only need to do the training once, pickling a trained tagger is a useful way to save it for later usage. If your trained tagger is called tagger, then here's how to dump and load it with pickle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b6967c8-4896-4ce6-8334-9fae64d0123a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "f = open('tagger.pickle', 'wb')\n",
    "pickle.dump(tagger, f)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4c82b084-ba9e-4a93-8430-267ab9dd7979",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f = open('tagger.pickle', 'rb')\n",
    "tagger = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8209b60e-cef7-4fc0-a53a-e9faa26942c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.775350744657889"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tagger.evaluate(test_sents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f977eded-027c-42ee-8362-94a2ee57be59",
   "metadata": {},
   "source": [
    "\n",
    "***\n",
    "## ***<a id=\"Training-and-combining-ngram-taggers\"></a>Training and combining ngram taggers:***\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71de7ff-6a65-4068-8075-abe0781ce70d",
   "metadata": {},
   "source": [
    "In addition to `UnigramTagger`, there are two more NgramTagger subclasses: `BigramTagger` and `TrigramTagger`. The BigramTagger subclass uses the previous tag as part of its context, while the TrigramTagger subclass uses the previous two tags. An `ngram` is a subsequence of *n* items, so the `BigramTagger` subclass looks at two items and the `TrigramTagger` subclass looks at three items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fcb836c0-6168-4dc8-8a53-4402b2b76cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11318799913662854"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from nltk.tag import BigramTagger, TrigramTagger\n",
    "bitagger = BigramTagger(train_sents)\n",
    "bitagger.evaluate(test_sents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c4a474c-2aef-40e7-bcf7-ae934431813c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06902654867256637"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "bitagger = TrigramTagger(train_sents)\n",
    "bitagger.evaluate(test_sents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a556892e-96cf-4677-81f6-1023111a3e56",
   "metadata": {},
   "source": [
    "Where `BigramTagger` and `TrigramTagger` can make a contribution is when we combine them with backoff tagging. This time, instead of creating each tagger individually, we will create a function that will take train_sents, a list of `SequentialBackoffTagger` classes, and an optional final backoff tagger, then train each tagger with the previous tagger as a backoff. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "56632c3c-ab55-4adf-9c15-f149c04317aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def backoff_tagger(train_sents, tagger_classes, backoff=None):\n",
    "    for cls in tagger_classes:\n",
    "        backoff = cls(train_sents, backoff=backoff)\n",
    "    return backoff\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "066d0e3e-2dce-4937-ba5e-2f29b4032992",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "backoff = DefaultTagger('NN')\n",
    "tagger = backoff_tagger(train_sents, [UnigramTagger, BigramTagger, TrigramTagger], backoff=backoff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "affe1810-7068-4626-83ae-bacb8771db2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8806388948845241"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tagger.evaluate(test_sents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ceb859f-9e04-4e83-9156-e634be19a8f6",
   "metadata": {},
   "source": [
    "**Quadgram tagger:**\n",
    "\n",
    "The `NgramTagger` class can be used by itself to create a tagger that uses more than three ngrams for its context key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "feb5afce-5857-4dac-a65a-d882f1c74849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.058493416792575005"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from nltk.tag import NgramTagger\n",
    "quadtagger = NgramTagger(4, train_sents)\n",
    "quadtagger.evaluate(test_sents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cbc29f-ac98-4ac8-b830-0fe2189bf390",
   "metadata": {},
   "source": [
    "It's even worse than the `TrigramTagger`, Here's an alternative implementation of a `QuadgramTagger` class that we can include in a list to `backoff_tagger`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "35f268ae-5c7a-4df3-9add-9f3dec7d8246",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class QuadgramTagger(NgramTagger):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        NgramTagger.__init__(self, 4, *args, **kwargs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d644c7be-1d8a-42bc-bbb1-a40fc71fefd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8805093891646881"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "quadtagger = backoff_tagger(train_sents, [UnigramTagger, BigramTagger, TrigramTagger, QuadgramTagger], backoff=backoff)\n",
    "quadtagger.evaluate(test_sents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45af466c-3038-45fb-b39a-e8c2ea6d6b7b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "***\n",
    "## ***<a id=\"Creating-a-model-of-likely-word-tags\"></a>Creating a model of likely word tags:***\n",
    "***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3964c0ff-228d-476d-a3eb-f977c8cd950e",
   "metadata": {},
   "source": [
    "A model of likely word tags involves estimating the probability of a word belonging to a particular part-of-speech (POS) based on its occurrence in a tagged corpus. This is useful for POS tagging tasks in NLP.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "af977fd2-fe1c-487a-9990-400a6702db5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.probability import FreqDist, ConditionalFreqDist\n",
    "def word_tag_model(words, tagged_words, limit=200):\n",
    "    fd = FreqDist(words)\n",
    "    cfd = ConditionalFreqDist(tagged_words)\n",
    "    most_freq = (word for word, count in fd.most_common(limit))\n",
    "    return dict((word, cfd[word].max()) for word in most_freq)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "be7a07ba-6588-4171-977a-a62d1a9b4a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5593352039715087"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from nltk.corpus import treebank\n",
    "model = word_tag_model(treebank.words(), treebank.tagged_words())\n",
    "tagger = UnigramTagger(model=model)\n",
    "tagger.evaluate(test_sents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ad5924-8ff7-4ea7-8949-8c21e4616354",
   "metadata": {},
   "source": [
    "An accuracy of almost `56%` is ok, but nowhere near as good as the trained UnigramTagger. Let's try adding it to our backoff chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a4a7c930-72c0-4df4-a752-5ce4c1a2a7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8806388948845241"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "default_tagger = DefaultTagger('NN')\n",
    "likely_tagger = UnigramTagger(model=model, backoff=default_tagger)\n",
    "tagger = backoff_tagger(train_sents, [UnigramTagger, BigramTagger, TrigramTagger], backoff=likely_tagger)\n",
    "tagger.evaluate(test_sents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c2e4e4-01f7-452c-81da-969148b4cbb7",
   "metadata": {},
   "source": [
    "The final accuracy is exactly the same as without the `likely_tagger`. This is because the frequency calculations we did to create the model are almost exactly the same as what happens when we train a UnigramTagger class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33336cc1-e854-483a-b477-2a9eac3de12a",
   "metadata": {},
   "source": [
    "\n",
    "***\n",
    "## ***<a id=\"Tagging-with-regular-expressions\"></a>Tagging with regular expressions:***\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9620489-0731-444f-b083-895682f52e6a",
   "metadata": {},
   "source": [
    "You can use regular expression matching to tag words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c01a3bc4-8c1e-46cf-abb9-5c24d39e2486",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "patterns = [\n",
    "  (r'^\\d+$', 'CD'),\n",
    "  (r'.*ing$', 'VBG'), # gerunds, i.e. wondering\n",
    "  (r'.*ment$', 'NN'), # i.e. wonderment\n",
    "  (r'.*ful$', 'JJ') # i.e. wonderful\n",
    " ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b651910-ce42-41e4-b97f-dea5235a2c8e",
   "metadata": {},
   "source": [
    "Once you have constructed this list of patterns, you can pass it into RegexpTagger.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "50f85605-56ca-43c8-acf4-20cf0e7ebcbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.037470321605870924"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from nltk.tag import RegexpTagger\n",
    "tagger = RegexpTagger(patterns)\n",
    "tagger.evaluate(test_sents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937ceaae-282d-40fd-b801-f39fed49ae8c",
   "metadata": {},
   "source": [
    "So, it is not too great with just a few patterns, but since RegexpTagger is a subclass of `SequentialBackoffTagger`, it can be a useful part of a backoff chain. For example, it could be positioned just before a `DefaultTagger` class, to tag words that the ngram \n",
    "tagger(s) missed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9dc815-ede2-44ab-ad0f-c8acb19ebdd8",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "***\n",
    "## ***<a id=\"Affix-tagging\"></a>Affix tagging:***\n",
    "***\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d4c8ac-ddfe-4480-a323-21f8bdb9ddd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb952706-c3a5-49f1-be49-e0f3a55a4f52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f076f6-5c4e-4a99-8111-7f794876c475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8f555f-014f-4477-a06a-7e993ac145c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2facb57a-47a2-4501-883d-7a052b24de50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e03817-ac8c-4aae-9911-0988e0710590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0cc6089f-a916-4720-bb25-e08b6d8dc7a2",
   "metadata": {},
   "source": [
    "\n",
    "***\n",
    "## ***<a id=\"Training-a-Brill-tagger\"></a>Training a Brill tagger:***\n",
    "***\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd525bb1-e345-461a-8733-73101cfaf73f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3210cdb4-177f-4ff9-86df-edfd7b318975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3323c423-4c7f-4d53-acb1-0ffe111af2b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857e16d9-9592-45dd-93a3-cee4f47369ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01533f0b-311e-44c3-bffd-a400ea94ab16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae421460-9e3b-43dc-84da-8e962857c8a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20927eb7-4ea5-48fc-9c8b-13eae098138a",
   "metadata": {},
   "source": [
    "\n",
    "***\n",
    "## ***<a id=\"Training-the-TnT-tagger\"></a>Training the TnT tagger:***\n",
    "***\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8db5844-c5e9-4a45-a558-c16be2420eae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31d4b82-4224-45b5-aceb-12e290afa2dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6676fc80-c5da-4e43-b09b-1bd029a95615",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09b6743-5e90-42df-b08c-ad7553854582",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65104be-74a0-48f0-b488-67278510c9c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f61956d-ce0b-409e-8045-be1127a26244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0cb4ea06-f2d9-4d7f-8a29-7809a91f1574",
   "metadata": {},
   "source": [
    "\n",
    "***\n",
    "## ***<a id=\"Using-WordNet-for-tagging\"></a>Using WordNet for tagging:***\n",
    "***\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb1b689-28b7-46c9-b86e-e8dcac8a3c12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029d0f1a-00ac-4386-8e9d-09631560f0ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409f1d59-896f-47c4-ad63-77d222e5ac93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f883bc8a-ba3a-4020-814d-cc29205ad940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a3ca53-5886-4954-bc73-6e46a4f2ddee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa72b44-2689-4507-bdf1-3dce14d732d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e705591-54d0-4739-87ac-35164e1aedfc",
   "metadata": {},
   "source": [
    "\n",
    "***\n",
    "## ***<a id=\"Tagging-proper-names\"></a>Tagging proper names:***\n",
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0282fc-246a-41d6-878c-2dac6a997fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293783e5-6844-4ced-b43c-b6be661d8bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c4e61e-3e74-40fc-aaf7-7471cdab18f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e8f73f-a2bf-4ecb-b3be-8c4b787b4a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cee5ec-1817-4e1e-b7d8-39ad09476d44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d1c214-32f8-4e48-b94b-1792d6f65fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "affdfde7-71dc-4e45-9e17-94443df8e13d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "***\n",
    "## ***<a id=\"Classifier-based-tagging\"></a>Classifier-based tagging:***\n",
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89e9de9-e04c-47f2-8d3a-a42dadbb2ff7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b45217-612e-43b7-849c-60d6db33dfea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14470995-efc9-48ce-879e-e1759a516b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c626e7df-bcac-4c0a-a6cc-99d2c83a93e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d88804c-ac65-4962-bda9-f81db68a9b83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffd7e91-10f0-4e04-9363-1e7789ea9cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "913946cc-13d8-4cb3-9b49-841a4eca478b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "***\n",
    "## ***<a id=\"Training-a-tagger-with-NLTK-Trainer\"></a>Training a tagger with NLTK-Trainer:***\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e28bb9-15e7-49ec-8c74-d1cbbf95f780",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0cbebc27-ebb6-4ab0-a6b8-2e3993a3b144",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "391bdfc7-02a2-4eda-80b8-66fc26a47608",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "561207bb-4f7b-48ae-868a-803d92101d87",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc56c9d5-ba17-405d-ad47-0762896bd571",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "739a6bbe-1095-4fff-ae39-0765c5e63ddb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
